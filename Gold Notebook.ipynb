{"cells":[{"cell_type":"markdown","source":["### Gold Notebook"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a8966fa7-db26-4515-872a-c812bf3c7f92"},{"cell_type":"code","source":["# Load in silver data\n","load_path = \"qa_lakehouse_1312.orders_silver\"\n","df = spark.read.table(load_path)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"63a525e7-9e49-4c53-be32-79313111749d"},{"cell_type":"markdown","source":["### dimdate_gold"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d07d1402-effd-43b4-9543-f887b8f12afd"},{"cell_type":"code","source":["# Instantiate dimdate_gold if not exists\n","\n","from pyspark.sql.types import *\n","from delta.tables import*\n","\n","# Define the schema for the dimdate_gold table\n","DeltaTable.createIfNotExists(spark) \\\n","    .tableName(\"dimdate_gold\") \\\n","    .addColumn(\"OrderDate\", DateType()) \\\n","    .addColumn(\"Day\", IntegerType()) \\\n","    .addColumn(\"Month\", IntegerType()) \\\n","    .addColumn(\"Year\", IntegerType()) \\\n","    .addColumn(\"mmmyyyy\", StringType()) \\\n","    .addColumn(\"yyyymm\", StringType()) \\\n","    .execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4c61a445-82f8-4c94-aac1-1c9602c5a2d5"},{"cell_type":"code","source":["from pyspark.sql.functions import col, dayofmonth, month, year, date_format\n","\n","# Create dataframe for dimDate_gold\n","\n","dfdimDate_gold = df.dropDuplicates([\"OrderDate\"]).select(col(\"OrderDate\"), \\\n","        dayofmonth(\"OrderDate\").alias(\"Day\"), \\\n","        month(\"OrderDate\").alias(\"Month\"), \\\n","        year(\"OrderDate\").alias(\"Year\"), \\\n","        date_format(col(\"OrderDate\"), \"MMM-yyyy\").alias(\"mmmyyyy\"), \\\n","        date_format(col(\"OrderDate\"), \"yyyyMM\").alias(\"yyyymm\"), \\\n","    ).orderBy(\"OrderDate\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc6c491e-be9a-4563-a719-cf71fad367c5"},{"cell_type":"code","source":["from delta.tables import *\n","from datetime import datetime \n","from pyspark.sql.types import *\n","from pyspark.sql.functions import * \n","import time\n","deltaTable = DeltaTable.forName(spark, 'dimdate_gold')\n","\n","start_time = time.time()\n","\n","table_name = \"dimdate_gold\"\n","load_path = \"qa_lakehouse_1312.dimdate_gold\"\n","\n","try:\n","    dfUpdates = dfdimDate_gold\n","\n","    record_count = dfUpdates.count()\n","\n","    deltaTable.alias('gold') \\\n","    .merge(\n","        dfUpdates.alias('updates'),\n","        'gold.OrderDate = updates.OrderDate'\n","    ) \\\n","    .whenMatchedUpdate(set =\n","        {\n","\n","        }\n","    ) \\\n","    .whenNotMatchedInsert(values =\n","        {\n","        \"OrderDate\": \"updates.OrderDate\",\n","        \"Day\": \"updates.Day\",\n","        \"Month\": \"updates.Month\",\n","        \"Year\": \"updates.Year\",\n","        \"mmmyyyy\": \"updates.mmmyyyy\",\n","        \"yyyymm\": \"updates.yyyymm\"\n","        }\n","    ) \\\n","    .execute()\n","\n","    load_status = \"SUCCESS\"\n","    error_message = None\n","\n","except Exception as e:\n","    record_count = 0\n","    load_status = \"FAILURE\"\n","    error_message = str(e)\n","\n","end_time = time.time()\n","duration = (end_time - start_time)\n","\n","monitoring_schema = StructType([\n","    StructField(\"load_timestamp\", TimestampType()),\n","    StructField(\"Table_name\", StringType()),\n","    StructField(\"Source_path\", StringType()),\n","    StructField(\"record_count\", IntegerType()),\n","    StructField(\"Status\", StringType()),\n","    StructField(\"error_message\", StringType()),\n","    StructField(\"duration\", FloatType())\n","])\n","\n","monitoring_data = [(datetime.now(), table_name, load_path, record_count, load_status, error_message, duration)]\n","\n","monitoring_df = spark.createDataFrame(monitoring_data, schema=monitoring_schema)\n","\n","monitoring_df.write.mode(\"append\").saveAsTable(\"monitoring_etl\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e496ad62-7f4f-4db3-aab6-7c3225309585"},{"cell_type":"markdown","source":["### dimcustomer_gold"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6b8274aa-987a-467b-a764-edc39f3a8f74"},{"cell_type":"code","source":["from pyspark.sql.types import *\n","from delta.tables import *\n","\n","# Create customer_gold dimension delta table\n","DeltaTable.createIfNotExists(spark) \\\n","    .tableName(\"dimcustomer_gold\") \\\n","    .addColumn(\"CustomerName\", StringType()) \\\n","    .addColumn(\"Email\",  StringType()) \\\n","    .addColumn(\"First\", StringType()) \\\n","    .addColumn(\"Last\", StringType()) \\\n","    .addColumn(\"CustomerID\", LongType()) \\\n","    .execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"91ce85d0-0826-4dcb-a232-20c961743138"},{"cell_type":"code","source":["from pyspark.sql.functions import col, split\n","\n","# Create customer_silver dataframe\n","\n","dfdimCustomer_silver = df.dropDuplicates([\"CustomerName\",\"Email\"]).select(col(\"CustomerName\"),col(\"Email\")) \\\n","    .withColumn(\"First\",split(col(\"CustomerName\"), \" \").getItem(0)) \\\n","    .withColumn(\"Last\",split(col(\"CustomerName\"), \" \").getItem(1)) "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2dc5ad3c-6f07-4af7-b71b-a927004bc068"},{"cell_type":"code","source":["from pyspark.sql.functions import monotonically_increasing_id, col, when, coalesce, max, lit\n","\n","dfdimCustomer_temp = spark.read.table(\"dimCustomer_gold\")\n","\n","MAXCustomerID = dfdimCustomer_temp.select(coalesce(max(col(\"CustomerID\")),lit(0)).alias(\"MAXCustomerID\")).first()[0]\n","\n","dfdimCustomer_gold = dfdimCustomer_silver.join(dfdimCustomer_temp,(dfdimCustomer_silver.CustomerName == dfdimCustomer_temp.CustomerName) & (dfdimCustomer_silver.Email == dfdimCustomer_temp.Email), \"left_anti\")\n","\n","dfdimCustomer_gold = dfdimCustomer_gold.withColumn(\"CustomerID\",monotonically_increasing_id() + MAXCustomerID + 1)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9c778de2-bd5c-4503-aeeb-25308c49106e"},{"cell_type":"code","source":["from delta.tables import *\n","\n","deltaTable = DeltaTable.forName(spark, 'dimcustomer_gold')\n","\n","dfUpdates = dfdimCustomer_gold\n","\n","deltaTable.alias('gold') \\\n",".merge(\n","    dfUpdates.alias('updates'),\n","    'gold.CustomerName = updates.CustomerName AND gold.Email = updates.Email'\n",") \\\n",".whenMatchedUpdate(set =\n","    {\n","\n","    }\n",") \\\n",".whenNotMatchedInsert(values =\n","    {\n","    \"CustomerName\": \"updates.CustomerName\",\n","    \"Email\": \"updates.Email\",\n","    \"First\": \"updates.First\",\n","    \"Last\": \"updates.Last\",\n","    \"CustomerID\": \"updates.CustomerID\"\n","    }\n",") \\\n",".execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a804d933-c995-4bea-bfc6-4961c0496baf"},{"cell_type":"markdown","source":["### dimproduct_gold"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1bcb16a6-eec9-4eae-b118-c223d218ffd1"},{"cell_type":"code","source":["from pyspark.sql.types import *\n","from delta.tables import *\n","\n","DeltaTable.createIfNotExists(spark) \\\n","    .tableName(\"dimproduct_gold\") \\\n","    .addColumn(\"ItemName\", StringType()) \\\n","    .addColumn(\"ItemID\", LongType()) \\\n","    .addColumn(\"ItemInfo\", StringType()) \\\n","    .execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4f6ab42f-3d30-4b6e-8dd6-0dc1b4f06802"},{"cell_type":"code","source":["from pyspark.sql.functions import col, split, lit, when\n","\n","# Create product_silver dataframe\n","\n","dfdimProduct_silver = df.dropDuplicates([\"Item\"]).select(col(\"Item\")) \\\n","    .withColumn(\"ItemName\",split(col(\"Item\"), \", \").getItem(0)) \\\n","    .withColumn(\"ItemInfo\",when((split(col(\"Item\"), \", \").getItem(1).isNull() | (split(col(\"Item\"), \", \").getItem(1)==\"\")),lit(\"\")).otherwise(split(col(\"Item\"), \", \").getItem(1))) "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bc230e10-fdcf-40c5-9857-ff920ad55c33"},{"cell_type":"code","source":["from pyspark.sql.functions import monotonically_increasing_id, col, lit, max, coalesce\n","\n","#dfdimProduct_temp = dfdimProduct_silver\n","dfdimProduct_temp = spark.read.table(\"dimProduct_gold\")\n","\n","MAXProductID = dfdimProduct_temp.select(coalesce(max(col(\"ItemID\")),lit(0)).alias(\"MAXItemID\")).first()[0]\n","\n","dfdimProduct_gold = dfdimProduct_silver.join(dfdimProduct_temp,(dfdimProduct_silver.ItemName == dfdimProduct_temp.ItemName) & (dfdimProduct_silver.ItemInfo == dfdimProduct_temp.ItemInfo), \"left_anti\")\n","\n","dfdimProduct_gold = dfdimProduct_gold.withColumn(\"ItemID\",monotonically_increasing_id() + MAXProductID + 1)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d502899-7d9b-4c57-ac12-2f40faf351d7"},{"cell_type":"code","source":["from delta.tables import *\n","\n","deltaTable = DeltaTable.forName(spark, 'dimproduct_gold')\n","\n","dfUpdates = dfdimProduct_gold\n","\n","deltaTable.alias('gold') \\\n",".merge(\n","        dfUpdates.alias('updates'),\n","        'gold.ItemName = updates.ItemName AND gold.ItemInfo = updates.ItemInfo'\n","        ) \\\n","        .whenMatchedUpdate(set =\n","        {\n","\n","        }\n","        ) \\\n","        .whenNotMatchedInsert(values =\n","        {\n","        \"ItemName\": \"updates.ItemName\",\n","        \"ItemInfo\": \"updates.ItemInfo\",\n","        \"ItemID\": \"updates.ItemID\"\n","        }\n","        ) \\\n","        .execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"258cbaa4-633a-4464-abb7-a33879e2618e"},{"cell_type":"markdown","source":["### factsales_gold"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"42d3cf7c-ea5b-4499-912e-b0954f2ab9b6"},{"cell_type":"code","source":["from pyspark.sql.types import *\n","from delta.tables import *\n","\n","DeltaTable.createIfNotExists(spark) \\\n","    .tableName(\"factsales_gold\") \\\n","    .addColumn(\"CustomerID\", LongType()) \\\n","    .addColumn(\"ItemID\", LongType()) \\\n","    .addColumn(\"OrderDate\", DateType()) \\\n","    .addColumn(\"Quantity\", IntegerType()) \\\n","    .addColumn(\"UnitPrice\", FloatType()) \\\n","    .addColumn(\"Tax\", FloatType()) \\\n","    .execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"697ab740-e0f0-4daa-b109-c75892ad239d"},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","dfdimCustomer_temp = spark.read.table(\"dimCustomer_gold\")\n","dfdimProduct_temp = spark.read.table(\"dimProduct_gold\")\n","\n","df = df.withColumn(\"ItemName\",split(col(\"Item\"), \", \").getItem(0)) \\\n","    .withColumn(\"ItemInfo\",when((split(col(\"Item\"), \", \").getItem(1).isNull() | (split(col(\"Item\"), \", \").getItem(1)==\"\")),lit(\"\")).otherwise(split(col(\"Item\"), \", \").getItem(1))) \\\n","\n","# Create Sales_gold dataframe\n","\n","dffactSales_gold = df.alias(\"df1\").join(dfdimCustomer_temp.alias(\"df2\"),(df.CustomerName == dfdimCustomer_temp.CustomerName) & (df.Email == dfdimCustomer_temp.Email), \"left\") \\\n","        .join(dfdimProduct_temp.alias(\"df3\"),(df.ItemName == dfdimProduct_temp.ItemName) & (df.ItemInfo == dfdimProduct_temp.ItemInfo), \"left\") \\\n","    .select(col(\"df2.CustomerID\") \\\n","        , col(\"df3.ItemID\") \\\n","        , col(\"df1.OrderDate\") \\\n","        , col(\"df1.Quantity\") \\\n","        , col(\"df1.UnitPrice\") \\\n","        , col(\"df1.Tax\") \\\n","    ).orderBy(col(\"df1.OrderDate\"), col(\"df2.CustomerID\"), col(\"df3.ItemID\"))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e7cd9df-c920-4e0d-84b7-38abe57b5dcc"},{"cell_type":"code","source":["from delta.tables import *\n","\n","deltaTable = DeltaTable.forName(spark, 'factsales_gold')\n","\n","dfUpdates = dffactSales_gold\n","\n","deltaTable.alias('gold') \\\n",".merge(\n","    dfUpdates.alias('updates'),\n","    'gold.OrderDate = updates.OrderDate AND gold.CustomerID = updates.CustomerID AND gold.ItemID = updates.ItemID'\n",") \\\n",".whenMatchedUpdate(set =\n","    {\n","\n","    }\n",") \\\n",".whenNotMatchedInsert(values =\n","    {\n","    \"CustomerID\": \"updates.CustomerID\",\n","    \"ItemID\": \"updates.ItemID\",\n","    \"OrderDate\": \"updates.OrderDate\",\n","    \"Quantity\": \"updates.Quantity\",\n","    \"UnitPrice\": \"updates.UnitPrice\",\n","    \"Tax\": \"updates.Tax\"\n","    }\n",") \\\n",".execute()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce31562a-a8d1-435d-b841-e44f2f15f249"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"23e82c2f-90ca-4d07-bacc-a15f48ec7914"}],"default_lakehouse":"23e82c2f-90ca-4d07-bacc-a15f48ec7914","default_lakehouse_name":"qa_lakehouse_1312","default_lakehouse_workspace_id":"5759f0e1-e7f2-4754-b11a-0e18bcadd153"}}},"nbformat":4,"nbformat_minor":5}